{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ebb57e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wikipedia\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer, DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "964560c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikipedia Data Scraping (Tagalog)\n",
    "wikipedia.set_lang(\"tl\")\n",
    "try:\n",
    "    text = wikipedia.page(\"Kultura ng Pilipinas\").content\n",
    "except wikipedia.exceptions.DisambiguationError as e:\n",
    "    print(f\"Disambiguation error. Options: {e.options}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a74d78e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking (Recursive)\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a3f96891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Embeddings (BGE-M3)\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f62001b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma Vector Store (Dense Retrieval)\n",
    "vectorstore = Chroma.from_texts(\n",
    "    texts=chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_name=\"filipino_culture\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "23fd0eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 Retriever\n",
    "bm25_retriever = BM25Retriever.from_texts(chunks)\n",
    "bm25_retriever.k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c1ce1a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#  DPR Setup (Dense Retriever #2)\n",
    "ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "\n",
    "q_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5a349c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed all chunks for DPR\n",
    "def encode_dpr_context(texts):\n",
    "    inputs = ctx_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        return ctx_encoder(**inputs).pooler_output.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2babfd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Store DPR embeddings + docs in a simple local structure\n",
    "dpr_embeddings = encode_dpr_context(chunks)\n",
    "dpr_docs = chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "331ff25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPR search function\n",
    "def dpr_retrieve(query, k=2):\n",
    "    inputs = q_tokenizer(query, return_tensors=\"pt\", truncation=True)\n",
    "    with torch.no_grad():\n",
    "        q_emb = q_encoder(**inputs).pooler_output.numpy()\n",
    "\n",
    "    similarities = np.dot(dpr_embeddings, q_emb.T).squeeze()\n",
    "    top_indices = similarities.argsort()[::-1][:k]\n",
    "    return [dpr_docs[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1536d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import Runnable\n",
    "\n",
    "\n",
    "class DPRRetriever(Runnable):\n",
    "    def __init__(self, docs, embeddings, query_fn):\n",
    "        self.docs = docs\n",
    "        self.embeddings = embeddings\n",
    "        self.query_fn = query_fn\n",
    "\n",
    "    def get_relevant_documents(self, query):\n",
    "        return [Document(page_content=doc) for doc in self.query_fn(query)]\n",
    "\n",
    "    async def aget_relevant_documents(self, query):\n",
    "        return self.get_relevant_documents(query)\n",
    "\n",
    "    def invoke(self, query, config=None):\n",
    "        return self.get_relevant_documents(query)\n",
    "    \n",
    "dpr_retriever = DPRRetriever(dpr_docs, dpr_embeddings, dpr_retrieve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0ea1b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[\n",
    "        vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "        bm25_retriever,\n",
    "        dpr_retriever\n",
    "    ],\n",
    "    weights=[0.5, 0.2, 0.3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a975b1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result 1\n",
      "------------------------------------------------------------\n",
      "Kabilang sa mga ibang sikat na ulam na may impluwensyang Timog-silangang Asyano at Kastila ang apritada, asado, chorizo, empanada, mani, paksiw, pandesal, pescado frito (pinritong isda), sisig, torta, kare-kare, kilawen, pinakbet, pinapaitan, at sinigang. Waring di-nakagaganang kainin sa paletang Kanluranin ang mga ilang kinakain ng mga Pilipino tu\n",
      "------------------------------------------------------------\n",
      "\n",
      "Result 2\n",
      "------------------------------------------------------------\n",
      ". Maaaring pag-uriin ang mga pista bilang mga Misa, prusisyon, parada, dulaan, seremonyang panrelihiyon o pangkultural, pakikipagkalakalan, eksibit, konsiyerto, paringal at iba't ibang laro at paligsahan.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Result 3\n",
      "------------------------------------------------------------\n",
      "Pakikisama: Ang pakikisama ay ang kaugaliang Pilipino na nagnanais magkaroon ng maganda at mabuting pakikitungo sa iba.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test Output\n",
    "query = \"Ano-ano ang mga ulam na dinala ng mga Kastila sa Pilipinas?\"\n",
    "results = ensemble_retriever.get_relevant_documents(query)\n",
    "\n",
    "for i, result in enumerate(results[:3], start=1):\n",
    "    print(f\"\\nResult {i}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(result.page_content.strip()[:350])  # First 350 characters\n",
    "    print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
