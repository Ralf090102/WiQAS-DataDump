{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ebb57e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wikipedia\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from sentence_transformers import CrossEncoder\n",
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer, DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "964560c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikipedia Data Scraping (Tagalog)\n",
    "wikipedia.set_lang(\"tl\")\n",
    "try:\n",
    "    pages = [\"Kultura ng Pilipinas\", \"Lutuing Pilipino\", \"Kasaysayan ng Pilipinas\", \"Talaan ng mga lungsod at bayan sa Pilipinas\"]\n",
    "    texts = [wikipedia.page(page).content for page in pages]\n",
    "except wikipedia.exceptions.DisambiguationError as e:\n",
    "    print(f\"Disambiguation error. Options: {e.options}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a3f96891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Embeddings (BGE-M3)\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e892a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking (Semantic)\n",
    "\n",
    "semantic_splitter = SemanticChunker(\n",
    "    embeddings=embedding_model,\n",
    "    breakpoint_threshold_type=\"standard_deviation\",\n",
    "    breakpoint_threshold_amount=0.75,\n",
    "    buffer_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b21ff2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Performing semantic chunking...\n",
      "[INFO] Total chunks generated: 174\n",
      "\n",
      "Chunk 1:\n",
      "Ang kultura ng Pilipinas o kalinangan ng Pilipinas ay pinaghalong impluwensiya ng mga katutubong tradisyon at mga kultura ng mga unang mangangalakal at mananakop nito noon. Ang pananakop ng mga Kastila sa Pilipinas, sa pamamahala ng Espa√±a, na tumagal ng mahigit 333 taon, ay may malaking kontribusyo...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Chunk 2:\n",
      "Bilang halimbawa, bawat taon, ang mga bayan sa buong bansa, ay nagsasagawa ng malalaking Pista, nagpapaalala sa mga Santong Patron ng mga bayan, barangay, o ng mga distrito. Ang mga Pista ay kadalasang may patimpalak sa katutubong pagsayaw, at sa ibang lugar ay mayroon pang sabungan. Ang mga ganiton...\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Performing semantic chunking...\")\n",
    "\n",
    "# Apply chunking to each page and concatenate results\n",
    "chunks = []\n",
    "for page in texts:\n",
    "    chunks.extend(semantic_splitter.split_text(page))\n",
    "\n",
    "print(f\"[INFO] Total chunks generated: {len(chunks)}\")\n",
    "\n",
    "# Print\n",
    "for i, chunk in enumerate(chunks[:2], start=1):\n",
    "    print(f\"\\nChunk {i}:\\n{chunk[:300]}...\\n{'-'*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f62001b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma Vector Store (Dense Retrieval)\n",
    "vectorstore = Chroma.from_texts(\n",
    "    texts=chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_name=\"filipino_culture\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "23fd0eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 Retriever\n",
    "bm25_retriever = BM25Retriever.from_texts(chunks)\n",
    "bm25_retriever.k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0ea1b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[\n",
    "        vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "        bm25_retriever\n",
    "    ],\n",
    "    weights=[0.7, 0.3]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1dc38cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Thesis\\DatasetDump\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\herna\\.cache\\huggingface\\hub\\models--cross-encoder--ms-marco-MiniLM-L-12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-12-v2\")\n",
    "\n",
    "def rerank_with_cross_encoder(query, docs, top_n=2):\n",
    "    pairs = [[query, doc.page_content] for doc in docs]\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    scored_docs = list(zip(scores, docs))\n",
    "    scored_docs.sort(key=lambda x: x[0], reverse=True)\n",
    "    return scored_docs[:top_n] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a975b1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rank 1 | Score: 6.7966\n",
      "------------------------------------------------------------\n",
      "Kabilang sa mga ibang sikat na ulam na may impluwensyang Timog-silangang Asyano at Kastila ang apritada, asado, chorizo, empanada, mani, paksiw, pandesal, pescado frito (pinritong isda), sisig, torta, kare-kare, kilawen, pinakbet, pinapaitan, at sinigang. Waring di-nakagaganang kainin sa paletang Ka\n",
      "------------------------------------------------------------\n",
      "\n",
      "Rank 2 | Score: 5.2829\n",
      "------------------------------------------------------------\n",
      "Ang kakulangan ng mga sandata ang naging sanhi ng pagkatalo ng mga Pilipinong sundalo laban sa mga Amerikano sa mga pangunahing labanan ngunit ang mga Pilipino ay nagwagi sa mga labanang gerilya. Ang Malolos, na kabisera ng pamahalaang rebolusyonaryo, ay nakuha ng mga Amerikano noong ika-31 ng Marso\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test Output\n",
    "query = \"Ano-ano ang mga ulam na dinala ng mga Kastila sa Pilipinas?\"\n",
    "\n",
    "# Retrieve documents using hybrid retriever\n",
    "initial_results = ensemble_retriever.get_relevant_documents(query)\n",
    "\n",
    "# Rerank using Cross-Encoder\n",
    "reranked = rerank_with_cross_encoder(query, initial_results, top_n=2)\n",
    "\n",
    "for i, (score, doc) in enumerate(reranked, start=1):\n",
    "    print(f\"\\nRank {i} | Score: {score:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(doc.page_content.strip()[:300])\n",
    "    print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
