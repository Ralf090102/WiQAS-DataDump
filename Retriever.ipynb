{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb57e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import fitz\n",
    "import json\n",
    "import torch\n",
    "import shutil\n",
    "import random\n",
    "import datetime\n",
    "import requests\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from statistics import mean\n",
    "from fuzzywuzzy import fuzz\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from sentence_transformers import CrossEncoder\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"knowledge_base\"\n",
    "data_dir = \"data\"\n",
    "result_dir = \"results\"\n",
    "html_dir = \"html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abd989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    print(f\"[INFO] Created directory: {data_dir}\")\n",
    "\n",
    "# Create result directory if it doesn't exist\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "    print(f\"[INFO] Created directory: {result_dir}\")\n",
    "\n",
    "# Create html directory if it doesn't exist\n",
    "if not os.path.exists(html_dir):\n",
    "    os.makedirs(html_dir)\n",
    "    print(f\"[INFO] Created directory: {html_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51619dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text extraction from PDF files\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.lower().endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(input_dir, filename)\n",
    "        json_filename = os.path.splitext(filename)[0] + \".json\"\n",
    "        json_path = os.path.join(data_dir, json_filename)\n",
    "\n",
    "        # Skip if already converted\n",
    "        if os.path.exists(json_path):\n",
    "            print(f\"[INFO] Skipping {filename} â€“ already converted.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"[INFO] Extracting: {filename}\")\n",
    "        doc = fitz.open(pdf_path)\n",
    "        data = {}\n",
    "\n",
    "        for page_number in tqdm(range(len(doc)), desc=f\"Processing {filename}\"):\n",
    "            page = doc[page_number]\n",
    "            text = page.get_text().strip()\n",
    "            if text:\n",
    "                data[f\"page_{page_number + 1}\"] = {\n",
    "                    \"page\": page_number + 1,\n",
    "                    \"content\": text\n",
    "                }\n",
    "\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"[INFO] Saved to: {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959709ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing function\n",
    "def clean_text(text):\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Fix ellipses or multiple punctuation\n",
    "    text = re.sub(r'\\.{3,}', '.', text)\n",
    "    text = re.sub(r'\\s+\\.', '.', text)\n",
    "    \n",
    "    # Remove stray characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae214a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "\n",
    "# Process all JSON files\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.lower().endswith(\".json\"):\n",
    "        json_path = os.path.join(data_dir, filename)\n",
    "        print(f\"[INFO] Preprocessing: {filename}\")\n",
    "        \n",
    "        # Load existing data\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Clean text for each page\n",
    "        for key in tqdm(data, desc=f\"Cleaning {filename}\"):\n",
    "            if \"content\" in data[key]:\n",
    "                data[key][\"content\"] = clean_text(data[key][\"content\"])\n",
    "        \n",
    "        # Overwrite file\n",
    "        with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"[INFO] Finished cleaning: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f7b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "model_name = \"gemma3:latest\"\n",
    "ollama_url = \"http://localhost:11434/api/generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e802830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_gemma(text, model=model_name):\n",
    "    prompt = (\n",
    "        f\"Given the following page content:\\n\\n\\\"\\\"\\\"\\n{text.strip()[:1500]}\\n\\\"\\\"\\\"\\n\\n\"\n",
    "        \"Categorize this page broadly in one word, and generate 2 to 3 relevant tags. \"\n",
    "        \"Return only this format:\\n\"\n",
    "        \"Category: <category>\\nTags: <comma-separated tags>\"\n",
    "    )\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(ollama_url, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"response\"]\n",
    "        else:\n",
    "            print(f\"[ERROR] Ollama responded with status {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Ollama request failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b20f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify a single page\n",
    "def classify_and_update(page_id, entry):\n",
    "    text = entry.get(\"content\", \"\").strip()\n",
    "    if not text or \"category\" in entry:\n",
    "        return page_id, None\n",
    "    \n",
    "    response = classify_with_gemma(text)\n",
    "    if response:\n",
    "        lines = response.strip().split(\"\\n\")\n",
    "        category, tags = \"unknown\", []\n",
    "        for line in lines:\n",
    "            if line.lower().startswith(\"category:\"):\n",
    "                category = line.split(\":\", 1)[1].strip()\n",
    "            elif line.lower().startswith(\"tags:\"):\n",
    "                tags = [tag.strip() for tag in line.split(\":\", 1)[1].split(\",\")]\n",
    "        \n",
    "        entry[\"category\"] = category\n",
    "        entry[\"tags\"] = tags\n",
    "        return page_id, entry\n",
    "    return page_id, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29abe446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of threads based on CPU cores\n",
    "physical_cores = multiprocessing.cpu_count() // 2\n",
    "max_threads = min(physical_cores * 2, 32)\n",
    "\n",
    "print(f\"[INFO] Using max_workers = {max_threads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf29181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply classification to all pages\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        path = os.path.join(data_dir, filename)\n",
    "        print(f\"\\n[INFO] Adding Gemma metadata to: {filename}\")\n",
    "\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            doc = json.load(f)\n",
    "\n",
    "        # Multithreading for pages in the doc\n",
    "        with ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "            futures = [executor.submit(classify_and_update, pid, doc[pid]) for pid in doc]\n",
    "            for future in tqdm(futures, desc=f\"Classifying {filename}\"):\n",
    "                page_id, result = future.result()\n",
    "                if result:\n",
    "                    doc[page_id] = result\n",
    "\n",
    "        # Save updated doc\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(doc, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"[INFO] Updated and saved: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f96891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Embeddings (BGE-M3)\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=256,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"?\", \"!\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45b4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "metadatas = []\n",
    "tag_counter = Counter()\n",
    "\n",
    "# Loop through each cleaned JSON file\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        print(f\"[INFO] Chunking file: {filename}\")\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:   \n",
    "            doc = json.load(f)\n",
    "\n",
    "        for key, entry in tqdm(doc.items(), desc=f\"Chunking {filename}\"):\n",
    "            text = entry.get(\"content\", \"\")\n",
    "            if not text.strip():\n",
    "                continue\n",
    "\n",
    "            split_chunks = splitter.split_text(text)\n",
    "\n",
    "            # Get and clean category\n",
    "            category = entry.get(\"category\", \"unknown\")\n",
    "            category = str(category).strip()\n",
    "\n",
    "            # Get and clean tags\n",
    "            raw_tags = entry.get(\"tags\", [])\n",
    "            if not isinstance(raw_tags, list):\n",
    "                raw_tags = [raw_tags]\n",
    "\n",
    "            tags = [str(tag).strip() for tag in raw_tags if isinstance(tag, (str, int, float, bool))]\n",
    "            tags = [tag for tag in tags if tag]\n",
    "            tag_counter.update(tags)\n",
    "\n",
    "            for i, chunk in enumerate(split_chunks):\n",
    "                if len(chunk.split()) <= 10:\n",
    "                    continue\n",
    "                \n",
    "                chunks.append(chunk)\n",
    "                metadatas.append({\n",
    "                    \"source\": filename,\n",
    "                    \"page\": entry.get(\"page\", key),\n",
    "                    \"chunk_id\": f\"{key}_chunk_{i}\",\n",
    "                    \"filename\": filename,\n",
    "                    \"category\": category,\n",
    "                    \"tags\": \", \".join(tags)\n",
    "                })\n",
    "\n",
    "print(f\"[INFO] Total chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846284d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch insert initialization\n",
    "batch_size = 256\n",
    "\n",
    "def embed_batch(batch_texts):\n",
    "    return embedding_model.embed_documents(batch_texts)\n",
    "\n",
    "batches = [(chunks[i:i+batch_size], metadatas[i:i+batch_size])\n",
    "           for i in range(0, len(chunks), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c6a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel embedding and collection\n",
    "embedded_batches = []\n",
    "with ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "    futures = {executor.submit(embed_batch, texts): (texts, metas)\n",
    "               for texts, metas in batches}\n",
    "\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Embedding\"):\n",
    "        try:\n",
    "            embeddings = future.result()\n",
    "            texts, metas = futures[future]\n",
    "            embedded_batches.append((texts, metas, embeddings))\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to embed batch: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62001b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear previous DB\n",
    "if os.path.exists(\"./chroma_db\"):\n",
    "    try:\n",
    "        if 'vectorstore' in locals():\n",
    "            del vectorstore\n",
    "            import gc\n",
    "            gc.collect()\n",
    "        shutil.rmtree(\"./chroma_db\")\n",
    "        print(\"[INFO] Successfully removed previous Chroma DB.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Could not fully clean Chroma DB: {e}\")\n",
    "else:\n",
    "    print(\"[INFO] No existing Chroma DB to remove.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462e46af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chroma\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_name=\"filipino_culture\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7949f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to generate stable unique IDs per chunk\n",
    "def get_chunk_id(meta):\n",
    "    return f\"{meta['filename'].replace('.json','')}_{meta['page']}_{meta['chunk_id']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d537b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index using Chroma's internal .upsert\n",
    "for texts, metas, embeds in tqdm(embedded_batches, desc=\"Indexing into Chroma\"):\n",
    "    ids = [get_chunk_id(meta) for meta in metas]\n",
    "\n",
    "    vectorstore._collection.upsert(\n",
    "        ids=ids,\n",
    "        documents=texts,\n",
    "        embeddings=embeds,\n",
    "        metadatas=metas\n",
    "    )\n",
    "\n",
    "print(\"[INFO] Finished indexing Chroma vector store.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3038e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eval_data(\n",
    "    file_path: str, \n",
    "    randomize: bool = False, \n",
    "    limit: Optional[int] = None\n",
    ") -> List[Dict[str, Any]]:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    if randomize:\n",
    "        random.shuffle(data)\n",
    "\n",
    "    if limit is not None:\n",
    "        data = data[:limit]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7224d0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(a: str, b: str) -> float:\n",
    "    a_tokens = set(a.lower().split())\n",
    "    b_tokens = set(b.lower().split())\n",
    "\n",
    "    if not a_tokens or not b_tokens:\n",
    "        return 0.0\n",
    "    \n",
    "    intersection = a_tokens.intersection(b_tokens)\n",
    "    union = a_tokens.union(b_tokens)\n",
    "    \n",
    "    return len(intersection) / len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_relevant(ground_truth: str, doc_content: str, threshold: float = 50, jaccard_threshold: float = 0.3) -> bool:\n",
    "    ground_truth = ground_truth.lower().strip()\n",
    "    doc_content = doc_content.lower().strip()\n",
    "\n",
    "    # Exact substring match\n",
    "    if ground_truth in doc_content or doc_content in ground_truth:\n",
    "        return True\n",
    "\n",
    "    # Bi-directional fuzzy match\n",
    "    similarity_1 = fuzz.partial_ratio(ground_truth, doc_content)\n",
    "    similarity_2 = fuzz.partial_ratio(doc_content, ground_truth)\n",
    "    if max(similarity_1, similarity_2) >= threshold:\n",
    "        return True\n",
    "    \n",
    "    # Jaccard similarity\n",
    "    jaccard = jaccard_similarity(ground_truth, doc_content)\n",
    "    if jaccard >= jaccard_threshold:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfea1829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_query_with_gemma(question: str) -> dict:\n",
    "    prompt = (\n",
    "        f\"Given the following question:\\n\\n\\\"{question}\\\"\\n\\n\"\n",
    "        \"Classify this question with:\\n\"\n",
    "        \"Category: <a broad category in one word>\\n\"\n",
    "        \"Tags: <comma-separated 2 to 3 relevant keywords>\"\n",
    "    )\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    response = requests.post(ollama_url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        output = response.json()[\"response\"]\n",
    "        category, tags = \"unknown\", []\n",
    "        for line in output.strip().split(\"\\n\"):\n",
    "            if line.lower().startswith(\"category:\"):\n",
    "                category = line.split(\":\", 1)[1].strip().strip(\"*\")\n",
    "            elif line.lower().startswith(\"tags:\"):\n",
    "                tags = [t.strip().strip(\"*\") for t in line.split(\":\", 1)[1].split(\",\")]\n",
    "        return {\"category\": category, \"tags\": tags}\n",
    "    else:\n",
    "        print(f\"[ERROR] Failed to classify: {question}\")\n",
    "        return {\"category\": \"unknown\", \"tags\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cbc5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_embedding_match(tags: List[str], doc_tags: List[str], threshold: float = 0.6) -> bool:\n",
    "    if not tags or not doc_tags:\n",
    "        return False\n",
    "\n",
    "    query_embeds = [embedding_model.embed_query(tag) for tag in tags]\n",
    "    doc_embeds = [embedding_model.embed_query(tag) for tag in doc_tags]\n",
    "\n",
    "    sims = [cosine_similarity([q], [d])[0][0] for q in query_embeds for d in doc_embeds]\n",
    "    return max(sims, default=0.0) >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9c0d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_by_metadata(query: str,\n",
    "                         category: str,\n",
    "                         tags: List[str],\n",
    "                         top_k: int = 3,\n",
    "                         verbose=False,\n",
    "                         category_threshold: float = 0.6,\n",
    "                         tag_sim_threshold: float = 0.6) -> List[Any]:\n",
    "\n",
    "    category_embedding = embedding_model.embed_query(category)\n",
    "    candidate_docs = vectorstore.similarity_search(query=query, k=50)\n",
    "\n",
    "    filtered_docs = []\n",
    "    seen = set()\n",
    "\n",
    "    category_pass = 0\n",
    "    tag_pass = 0\n",
    "    total_skipped_no_meta = 0\n",
    "\n",
    "    for doc in candidate_docs:\n",
    "        doc_meta = doc.metadata or {}\n",
    "        doc_cat = doc_meta.get(\"category\", \"\").strip()\n",
    "        if not doc_cat:\n",
    "            total_skipped_no_meta += 1\n",
    "            continue\n",
    "\n",
    "        doc_cat_embedding = embedding_model.embed_query(doc_cat)\n",
    "        cat_sim = cosine_similarity([category_embedding], [doc_cat_embedding])[0][0]\n",
    "        if cat_sim < category_threshold:\n",
    "            continue\n",
    "        category_pass += 1\n",
    "\n",
    "        doc_tags = doc_meta.get(\"tags\", \"\")\n",
    "        if isinstance(doc_tags, str):\n",
    "            doc_tags = [t.strip() for t in doc_tags.split(\",\") if t.strip()]\n",
    "\n",
    "        if not tag_embedding_match(tags, doc_tags, threshold=tag_sim_threshold):\n",
    "            continue\n",
    "        tag_pass += 1\n",
    "\n",
    "        snippet = doc.page_content[:50].strip().lower()\n",
    "        if snippet in seen:\n",
    "            continue\n",
    "\n",
    "        seen.add(snippet)\n",
    "        filtered_docs.append(doc)\n",
    "        if len(filtered_docs) >= top_k:\n",
    "            break\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\n[INFO] Retrieved: {len(candidate_docs)} Top: candidates for query: \\\"{query[:128]}...\\\"\")\n",
    "        print(f\"[INFO] Skipped (missing metadata): {total_skipped_no_meta}\")\n",
    "        print(f\"[INFO] Passed category filter: {category_pass}\")\n",
    "        print(f\"[INFO] Passed tag filter: {tag_pass}\")\n",
    "        print(f\"[INFO] Final top-k after deduplication: {len(filtered_docs)}\\n\")\n",
    "\n",
    "    return filtered_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1d0e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retriever(\n",
    "    eval_data: list,\n",
    "    reranker,\n",
    "    k=3,\n",
    "    fuzzy_threshold=70,\n",
    "    jaccard_threshold=0.4,\n",
    "    doc_content_key=\"page_content\"\n",
    "):\n",
    "    hits = 0\n",
    "    relevant_docs_total = 0\n",
    "    retrieved_docs_total = 0\n",
    "    reciprocal_ranks = []\n",
    "    results_flat = []\n",
    "\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    timestamp = datetime.datetime.now().strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "    file_path = f\"result_{timestamp}\"\n",
    "    csv_path = f\"results/{file_path}.csv\"\n",
    "\n",
    "    tqdm_params = dict(\n",
    "        desc=\"Evaluating\",\n",
    "        dynamic_ncols=True,\n",
    "        file=sys.stdout,\n",
    "        leave=True,\n",
    "        mininterval=900.0   # 15 minutes\n",
    "    )\n",
    "\n",
    "    for idx, sample in enumerate(tqdm(eval_data, **tqdm_params)):\n",
    "        question = sample[\"question\"]\n",
    "        ground_truth = sample[\"answer\"]\n",
    "\n",
    "        classification = classify_query_with_gemma(question)\n",
    "        category = classification[\"category\"]\n",
    "        tags = classification[\"tags\"]\n",
    "\n",
    "        if not category or category.lower() == \"unknown\":\n",
    "            print(f\"[WARN] Question {idx+1} got weak category from Gemma: {question[:60]}...\")\n",
    "\n",
    "        try:\n",
    "            initial_docs = retrieve_by_metadata(question, category, tags, top_k=k, verbose=False)\n",
    "            if not initial_docs:\n",
    "                reciprocal_ranks.append(0)\n",
    "                results_flat.append({\n",
    "                    \"item\": idx + 1,\n",
    "                    \"query\": question,\n",
    "                    \"ground_truth\": ground_truth,\n",
    "                    \"category\": category,\n",
    "                    \"tags\": \", \".join(tags),\n",
    "                    \"rank\": 1,\n",
    "                    \"score\": \"N/A\",\n",
    "                    \"found\": False,\n",
    "                    \"doc_content\": \"[NO DOCUMENTS RETRIEVED]\"\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            reranked = reranker(question, initial_docs, top_n=k)\n",
    "            if not reranked:\n",
    "                reciprocal_ranks.append(0)\n",
    "                results_flat.append({\n",
    "                    \"item\": idx + 1,\n",
    "                    \"query\": question,\n",
    "                    \"ground_truth\": ground_truth,\n",
    "                    \"category\": category,\n",
    "                    \"tags\": \", \".join(tags),\n",
    "                    \"rank\": 1,\n",
    "                    \"score\": \"N/A\",\n",
    "                    \"found\": False,\n",
    "                    \"doc_content\": \"[NO DOCUMENTS RERANKED]\"\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            found = False\n",
    "            retrieved_docs_total += len(reranked)\n",
    "\n",
    "            for rank, (score, doc) in enumerate(reranked):\n",
    "                doc_content = getattr(doc, doc_content_key, doc)\n",
    "                if isinstance(doc_content, dict):\n",
    "                    doc_content = doc_content.get(\"content\", \"\")\n",
    "\n",
    "                if is_relevant(ground_truth, doc_content, fuzzy_threshold, jaccard_threshold):\n",
    "                    relevant_docs_total += 1\n",
    "                    if not found:\n",
    "                        hits += 1\n",
    "                        reciprocal_ranks.append(1 / (rank + 1))\n",
    "                        found = True\n",
    "\n",
    "                results_flat.append({\n",
    "                    \"item\": idx + 1,\n",
    "                    \"query\": question,\n",
    "                    \"ground_truth\": ground_truth,\n",
    "                    \"category\": category,\n",
    "                    \"tags\": \", \".join(tags),\n",
    "                    \"rank\": rank + 1,\n",
    "                    \"score\": f\"{score:.4f}\",\n",
    "                    \"found\": found,\n",
    "                    \"doc_content\": doc_content[:500]\n",
    "                })\n",
    "\n",
    "            # If nothing relevant was found, log rank 1 again with found=False\n",
    "            if not found:\n",
    "                reciprocal_ranks.append(0)\n",
    "                if reranked:\n",
    "                    score, doc = reranked[0]\n",
    "                    doc_content = getattr(doc, doc_content_key, doc)\n",
    "                    if isinstance(doc_content, dict):\n",
    "                        doc_content = doc_content.get(\"content\", \"\")\n",
    "\n",
    "                    results_flat.append({\n",
    "                        \"item\": idx + 1,\n",
    "                        \"query\": question,\n",
    "                        \"ground_truth\": ground_truth,\n",
    "                        \"category\": category,\n",
    "                        \"tags\": \", \".join(tags),\n",
    "                        \"rank\": 1,\n",
    "                        \"score\": f\"{score:.4f}\",\n",
    "                        \"found\": False,\n",
    "                        \"doc_content\": doc_content[:500]\n",
    "                    })\n",
    "\n",
    "        except Exception as e:\n",
    "            reciprocal_ranks.append(0)\n",
    "            results_flat.append({\n",
    "                \"item\": idx + 1,\n",
    "                \"query\": question,\n",
    "                \"ground_truth\": ground_truth,\n",
    "                \"category\": category,\n",
    "                \"tags\": \", \".join(tags),\n",
    "                \"rank\": \"error\",\n",
    "                \"score\": \"N/A\",\n",
    "                \"found\": False,\n",
    "                \"doc_content\": f\"[ERROR] {str(e)}\"\n",
    "            })\n",
    "\n",
    "    # Save output\n",
    "    df = pd.DataFrame(results_flat)\n",
    "\n",
    "    df.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "    print(f\"\\n[INFO] Saved CSV results to: {csv_path}\")\n",
    "\n",
    "    df.to_html(f\"html/{file_path}.html\")\n",
    "    print(f\"[INFO] Saved HTML results to: html/{file_path}.html\")\n",
    "\n",
    "    total_queries = len(eval_data)\n",
    "    metrics = {\n",
    "        f\"Recall@{k}\": hits / total_queries if total_queries > 0 else 0.0,\n",
    "        f\"Precision@{k}\": relevant_docs_total / retrieved_docs_total if retrieved_docs_total > 0 else 0.0,\n",
    "        f\"MRR@{k}\": np.mean(reciprocal_ranks) if reciprocal_ranks else 0.0\n",
    "    }\n",
    "\n",
    "    return metrics, file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4388300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-12-v2\")\n",
    "\n",
    "def rerank_with_cross_encoder(query, docs, top_n=3, verbose=False):\n",
    "    pairs = [[query, doc.page_content] for doc in docs]\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    normalized_scores = [score / (len(doc.page_content.split()) + 1) for score, doc in zip(scores, docs)]\n",
    "    scored_docs = list(zip(normalized_scores, docs))\n",
    "    scored_docs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    if verbose:\n",
    "        for i, (score, doc) in enumerate(scored_docs[:top_n], start=1):\n",
    "            print(f\"\\nRank {i} Score: {score:.4f}\")\n",
    "            print(doc.page_content[:300] + \"...\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "    return scored_docs[:top_n] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be369b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = load_eval_data(\"evaluation.json\", randomize=False, limit=750)\n",
    "\n",
    "results, file_path = evaluate_retriever(\n",
    "    eval_data=eval_data,\n",
    "    reranker=rerank_with_cross_encoder,\n",
    "    k=3,\n",
    "    fuzzy_threshold=60,\n",
    "    jaccard_threshold = 0.4,\n",
    "    doc_content_key='page_content'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce91eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvaluation Results:\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad99b419",
   "metadata": {},
   "source": [
    "# View Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32adec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"results/{file_path}.csv\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d837418c",
   "metadata": {},
   "source": [
    "# SINGLE QUERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427e5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Output\n",
    "query = \"What is the most famous Filipino dish?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b461f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify with Gemma\n",
    "classification = classify_query_with_gemma(query)\n",
    "category = classification[\"category\"]\n",
    "tags = classification[\"tags\"]\n",
    "\n",
    "print(f\"[INFO] Category: {category}\")\n",
    "print(f\"[INFO] Tags: {tags}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f18f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve documents by category and tags\n",
    "initial_docs = retrieve_by_metadata(query, category, tags, top_k=10, verbose=True)\n",
    "\n",
    "if not initial_docs:\n",
    "    print(\"[WARN] No documents found after filtering.\")\n",
    "else:\n",
    "    reranked = rerank_with_cross_encoder(query, initial_docs, top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b66a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print output\n",
    "for i, (score, doc) in enumerate(reranked, start=1):\n",
    "    print(f\"\\nRank {i} | Score: {score:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(doc.page_content.strip()[:300])\n",
    "    print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
